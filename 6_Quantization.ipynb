{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "4c9f7994-acb8-431c-965b-455bd559dfb4",
          "showTitle": false,
          "title": ""
        },
        "id": "COuEY7ceDzTt"
      },
      "source": [
        "# Understanding and Applying Quantization\n",
        "\n",
        "Quantization is a  can allow models to run faster and use less memory. By converting 32-bit floating-point numbers (the `float32` data type) into lower-precision formats, like 8-bit integers (the `int8` data type), we can reduce the computational requirements of our models. Let's start with the basics and gradually move towards quantizing complex models like CNNs.\n",
        "\n",
        "\n",
        "1. Explore how to quantize a a single variable and a function in pytorch\n",
        "1. Apply quantization to a neural network\n",
        "1. Compare the size and performance of quantized convolutional neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "4559bd02-18eb-4d81-b40f-a8179ca7596d",
          "showTitle": false,
          "title": ""
        },
        "id": "WgG26PwMDzTv",
        "outputId": "ffcc6fca-24c9-4578-e34a-37c04776c536"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "Command skipped",
              "errorTraceType": "html",
              "metadata": {},
              "type": "ipynbError"
            }
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import sys\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "64d36852-3b9e-4460-b429-ac0e347e5bfa",
          "showTitle": false,
          "title": ""
        },
        "id": "8YYDP1yoDzTv"
      },
      "source": [
        "# Section 1 - Quantization\n",
        "\n",
        " illustrate both 4-bit and 8-bit quantization. As for the neural network part, it create a simple model and show how to quantize and dequantize its weights. Since we can't download data or train models in this environment, I'll present the code you would use to do it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "09fc82a3-8489-44ec-8b33-0bbff9f7b967",
          "showTitle": false,
          "title": ""
        },
        "id": "TaWyw-FgDzTv"
      },
      "source": [
        "### 1. Quantization of a Single Value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "45a06c63-fd2d-43e2-bc57-58a9d0dd027c",
          "showTitle": false,
          "title": ""
        },
        "id": "sWLYg_bxDzTv",
        "outputId": "ed016381-3b99-4b22-ba68-c5077440db62"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "Command skipped",
              "errorTraceType": "html",
              "metadata": {},
              "type": "ipynbError"
            }
          }
        }
      ],
      "source": [
        "# Let's start by defining the quantize and unquantize functions:\n",
        "\n",
        "def quantize(value, bits):\n",
        "    \"\"\"\n",
        "    Quantizes a floating point number to an integer, given a certain number of bits.\n",
        "    The range is from -1.0 to 1.0.\n",
        "\n",
        "    Args:\n",
        "    value (float): The value to be quantized.\n",
        "    bits (int): The number of bits used for quantization.\n",
        "\n",
        "    Returns:\n",
        "    int: The quantized value.\n",
        "    \"\"\"\n",
        "    assert -1.0 <= value <= 1.0, \"Value out of range\"\n",
        "    quantized_value = np.round(value * (2**(bits - 1) - 1))\n",
        "    return int(quantized_value)\n",
        "\n",
        "def unquantize(quantized_value, bits):\n",
        "    \"\"\"\n",
        "    Unquantizes an integer back to a floating point number, given the original number of bits.\n",
        "    The range is from -1.0 to 1.0.\n",
        "\n",
        "    Args:\n",
        "    quantized_value (int): The value to be unquantized.\n",
        "    bits (int): The number of bits used for quantization.\n",
        "\n",
        "    Returns:\n",
        "    float: The unquantized value.\n",
        "    \"\"\"\n",
        "    value = quantized_value / (2**(bits - 1) - 1)\n",
        "    return float(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d028af61-8d81-4d06-bf17-55e7e8db753d",
          "showTitle": false,
          "title": ""
        },
        "id": "qR8UcUFjDzTv",
        "outputId": "9e857691-c471-4b3f-efd6-7787640dbb3a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "Command skipped",
              "errorTraceType": "html",
              "metadata": {},
              "type": "ipynbError"
            }
          }
        }
      ],
      "source": [
        "# Test the quantize and unquantize functions with 4 and 8 bits\n",
        "value = 0.5\n",
        "quantized_value_4bit = quantize(value, bits=4)\n",
        "unquantized_value_4bit = unquantize(quantized_value_4bit, bits=4)\n",
        "\n",
        "quantized_value_8bit = quantize(value, bits=8)\n",
        "unquantized_value_8bit = unquantize(quantized_value_8bit, bits=8)\n",
        "\n",
        "print(f\"Original Value: {value}\\n----\\n4-bit Quantization:{quantized_value_4bit}\\n4-bit Unquantization: {unquantized_value_4bit}\\n----\\n8-bit Quantization:{quantized_value_8bit}\\n8-bit Unquantization: {unquantized_value_8bit}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "13df4fed-d683-4ea5-903c-86303c453d6f",
          "showTitle": false,
          "title": ""
        },
        "id": "1J02W1e9DzTw"
      },
      "source": [
        "### 2. Quantization of a Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "67e12130-052b-4c34-ac5f-db9f16b6b3f3",
          "showTitle": false,
          "title": ""
        },
        "id": "sgV86qP4DzTw",
        "outputId": "7e0a2ba1-a5ed-4d5c-c879-6724cec02a7b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "Command skipped",
              "errorTraceType": "html",
              "metadata": {},
              "type": "ipynbError"
            }
          }
        }
      ],
      "source": [
        "# # Generate values\n",
        "x = np.linspace(-1, 1, 100)\n",
        "y = np.sin(np.pi * x)\n",
        "\n",
        "# Quantize and unquantize values for 4 and 8 bits\n",
        "y_quantized_4bit = np.array([quantize(val, bits=4) for val in y])\n",
        "y_unquantized_4bit = np.array([unquantize(val, bits=4) for val in y_quantized_4bit])\n",
        "\n",
        "y_quantized_8bit = np.array([quantize(val, bits=8) for val in y])\n",
        "y_unquantized_8bit = np.array([unquantize(val, bits=8) for val in y_quantized_8bit])\n",
        "\n",
        "# Calculate quantization loss for 4 and 8 bits\n",
        "loss_4bit = np.mean((y - y_unquantized_4bit)**2)\n",
        "loss_8bit = np.mean((y - y_unquantized_8bit)**2)\n",
        "\n",
        "print(f\"Loss of 4-bit quantization: {loss_4bit}\\nLoss of 8-bit quantization: {loss_8bit}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "76457e94-344c-4813-a414-b0eeb3119a7d",
          "showTitle": false,
          "title": ""
        },
        "id": "HcWlfCyhDzTw",
        "outputId": "b2e262b3-16f1-41ac-d87e-10d833cc2f5c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "Command skipped",
              "errorTraceType": "html",
              "metadata": {},
              "type": "ipynbError"
            }
          }
        }
      ],
      "source": [
        "# Plot original, quantized and unquantized values\n",
        "plt.figure(figsize=(10, 12))\n",
        "\n",
        "plt.subplot(4, 1, 1)\n",
        "plt.plot(x, y, label=\"Original\")\n",
        "plt.title(\"Original\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(4, 1, 2)\n",
        "plt.scatter(x, y_quantized_4bit, label=\"Quantized 4 bit\", marker=\"s\")\n",
        "plt.legend()\n",
        "plt.title(\"Quantized\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(4, 1, 3)\n",
        "plt.scatter(x, y_quantized_8bit, label=\"Quantized 8 bit\", marker=\"s\")\n",
        "plt.legend()\n",
        "plt.title(\"Quantized\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(4, 1, 4)\n",
        "plt.plot(x, y_unquantized_4bit, label=\"Unquantized 4 bit\")\n",
        "plt.plot(x, y_unquantized_8bit, label=\"Unquantized 8 bit\")\n",
        "plt.legend()\n",
        "plt.title(\"Unquantized\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b75e27dd-3bee-4e08-a91a-14e259659527",
          "showTitle": false,
          "title": ""
        },
        "id": "b98bZMmODzTx"
      },
      "source": [
        "### 3. Quantization of a Simple Neural Network\n",
        "let's apply quantization to a neural network. We'll create a simple network with one hidden layer, then we'll quantize and dequantize its weights.\n",
        "\n",
        "In PyTorch, [quantization](https://pytorch.org/docs/stable/quantization.html) is achieved using a `QuantStub` and `DeQuantStub` to mark the points in the model where the data needs to be converted to quantized form and converted back to floating point form, respectively. After defining the network with these stubs, we use the `torch.quantization.prepare` and `torch.quantization.convert` functions to quantize the model.\n",
        "\n",
        "The process of quantizing a model in PyTorch involves the following steps:\n",
        "\n",
        "- Define a neural network and mark the points in the model where the data needs to be converted to quantized form and converted back to floating point form. This is done using a `QuantStub` and `DeQuantStub`.\n",
        "- Specify a quantization configuration for the model using `torch.quantization.get_default_qconfig`. This sets up the quantization parameters.\n",
        "- Prepare the model for quantization using `torch.quantization.prepare`. This function replaces specified modules in the model with their quantized counterparts.\n",
        "- Calibrate the model on a calibration dataset. During calibration, the model is run on a calibration dataset and the range of the activations is observed. This is used to determine the parameters for quantization.\n",
        "- Convert the prepared and calibrated model to a quantized version using torch.quantization.convert. This function changes these modules to use quantized weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "fd999b50-347b-4d28-a9e7-a81e689525f5",
          "showTitle": false,
          "title": ""
        },
        "id": "lLjJxi4ODzTx"
      },
      "outputs": [],
      "source": [
        "# Define the network architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # QuantStub will act as a placeholder for the quantization process, it simulates quantization of inputs to the model.\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "\n",
        "        # Define two fully connected layers (aka linear layers) for our simple neural network\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)  # Input size is 28*28 (size of a flattened MNIST image), output size is 128\n",
        "        self.fc2 = nn.Linear(128, 10)  # Input size is 128 (output of previous layer), output size is 10 (for 10 classes)\n",
        "\n",
        "        # DeQuantStub simulates the dequantization of the final output of the model, converting it back to a floating point number.\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Reshape the input tensor to a vector of size 28*28\n",
        "        x = x.view(-1, 28 * 28)\n",
        "\n",
        "        # Pass the input through the QuantStub, which will simulate the quantization of the input tensor\n",
        "        x = self.quant(x)\n",
        "\n",
        "        # Apply the first fully connected layer and ReLU activation function\n",
        "        x = torch.relu(self.fc1(x))\n",
        "\n",
        "        # Apply the second fully connected layer\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # Pass the output through the DeQuantStub, which will simulate the dequantization of the output tensor\n",
        "        x = self.dequant(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "53035bc7-f957-4266-ae46-fd500dc3fc8c",
          "showTitle": false,
          "title": ""
        },
        "id": "gHehF-IuDzTx",
        "outputId": "2829bbca-a749-4c81-ef41-d12daac0cf31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-04 20:38:56--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\r\nResolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\r\nConnecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... failed: Connection timed out.\r\nRetrying.\r\n\r\n--2023-10-04 20:41:07--  (try: 2)  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\r\nConnecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... failed: Connection timed out.\r\nRetrying.\r\n\r\n--2023-10-04 20:43:19--  (try: 3)  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\r\nConnecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... failed: Connection timed out.\r\nRetrying.\r\n\r\n--2023-10-04 20:45:33--  (try: 4)  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\r\nConnecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... failed: Connection timed out.\r\nRetrying.\r\n\r\n--2023-10-04 20:47:47--  (try: 5)  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\r\nConnecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... failed: Connection timed out.\r\nRetrying.\r\n\r\n--2023-10-04 20:50:03--  (try: 6)  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\r\nConnecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... failed: Connection timed out.\r\nRetrying.\r\n\r\n--2023-10-04 20:52:19--  (try: 7)  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\r\nConnecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... failed: Connection timed out.\r\nRetrying.\r\n\r\n--2023-10-04 20:54:35--  (try: 8)  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\r\nConnecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... failed: Connection timed out.\r\nRetrying.\r\n\r\n--2023-10-04 20:56:54--  (try: 9)  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\r\nConnecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... failed: Connection timed out.\r\nRetrying.\r\n\r\n--2023-10-04 20:59:12--  (try:10)  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\r\nConnecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... failed: Connection timed out.\r\nRetrying.\r\n\r\n--2023-10-04 21:01:32--  (try:11)  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\r\nConnecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... failed: Connection timed out.\r\nRetrying.\r\n\r\n--2023-10-04 21:03:51--  (try:12)  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\r\nConnecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... failed: Connection timed out.\r\nRetrying.\r\n\r\n--2023-10-04 21:06:11--  (try:13)  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\r\nConnecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... "
          ]
        }
      ],
      "source": [
        "# Load the MNIST dataset\n",
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "train_set = MNIST('./', download=True,\n",
        "transform=transforms.Compose([\n",
        "transforms.ToTensor(),\n",
        "]), train=True)\n",
        "\n",
        "\n",
        "test_set = MNIST('./', download=True,\n",
        "transform=transforms.Compose([\n",
        "transforms.ToTensor(),\n",
        "]), train=False)\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "trainset = torchvision.datasets.MNIST(root=DA.paths.working_dir, train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "net = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6b7f29fe-3f7b-477c-b0f2-0de832a0d6d3",
          "showTitle": false,
          "title": ""
        },
        "id": "smxWQHqdDzTy",
        "outputId": "a7854ce1-5a1c-4ffc-e2da-7a61e3fa478b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "Command skipped",
              "errorTraceType": "html",
              "metadata": {},
              "type": "ipynbError"
            }
          }
        }
      ],
      "source": [
        "# Train the network\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:    # print every 200 mini-batches\n",
        "            print(\"[%d, %5d] loss: %.3f\" %\n",
        "                  (epoch + 1, i + 1, running_loss / 200))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d7daba91-9f4c-44c6-aef6-2bcc509d52af",
          "showTitle": false,
          "title": ""
        },
        "id": "RCd31r9LDzTy",
        "outputId": "e7618327-d368-44c3-b627-bd504984eb3e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "Command skipped",
              "errorTraceType": "html",
              "metadata": {},
              "type": "ipynbError"
            }
          }
        }
      ],
      "source": [
        "# Specify quantization configuration\n",
        "net.qconfig = torch.ao.quantization.get_default_qconfig(\"onednn\")\n",
        "\n",
        "# Prepare the model for static quantization. This inserts observers in the model that will observe activation tensors during calibration.\n",
        "net_prepared = torch.quantization.prepare(net)\n",
        "\n",
        "# Now we convert the model to a quantized version.\n",
        "net_quantized = torch.quantization.convert(net_prepared)\n",
        "\n",
        "# Once the model is quantized, it can be used for inference in the same way as the unquantized model, but it will use less memory and potentially have faster inference times, at the cost of a possible decrease in accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2c06cad7-e78b-48e6-adaf-718e86a6970b",
          "showTitle": false,
          "title": ""
        },
        "id": "OErk_l2CDzTy",
        "outputId": "5aab4811-bc56-4ade-a6bf-9c486032186b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "Command skipped",
              "errorTraceType": "html",
              "metadata": {},
              "type": "ipynbError"
            }
          }
        }
      ],
      "source": [
        "# Let's look at the sizes of these two models on disk and see how much we save by quantization\n",
        "buf = io.BytesIO()\n",
        "torch.save(net.state_dict(), buf)\n",
        "size_original = sys.getsizeof(buf.getvalue())\n",
        "\n",
        "buf = io.BytesIO()\n",
        "torch.save(net_quantized.state_dict(), buf)\n",
        "size_quantized = sys.getsizeof(buf.getvalue())\n",
        "\n",
        "print(\"Size of the original model: \", size_original)\n",
        "print(\"Size of the quantized model: \", size_quantized)\n",
        "print(f\"The quantized model is {np.round(100.*(size_quantized )/ size_original)}% the size of the original model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d1a98efd-f476-43bb-997e-5861f3a1e916",
          "showTitle": false,
          "title": ""
        },
        "id": "a4Q80SriDzTy",
        "outputId": "7415595e-e28c-4313-986c-2e782de2bab1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "Command skipped",
              "errorTraceType": "html",
              "metadata": {},
              "type": "ipynbError"
            }
          }
        }
      ],
      "source": [
        "# Print out the weights of the original network\n",
        "for name, param in net.named_parameters():\n",
        "    print(\"Original Network Layer:\", name)\n",
        "    print(param.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "722b83e5-49b3-49ac-8059-450df1caa2d8",
          "showTitle": false,
          "title": ""
        },
        "id": "hyPJooLTDzTz",
        "outputId": "22deb067-ab3c-44f6-f938-2f1633f0a222"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "Command skipped",
              "errorTraceType": "html",
              "metadata": {},
              "type": "ipynbError"
            }
          }
        }
      ],
      "source": [
        "# Print out the weights of the quantized network\n",
        "for name, module in net_quantized.named_modules():\n",
        "    if isinstance(module, nn.quantized.Linear):\n",
        "        print(\"Quantized Network Layer:\", name)\n",
        "\n",
        "        print(\"Weight:\")\n",
        "        print(module.weight())\n",
        "\n",
        "        print(\"Bias:\")\n",
        "        print(module.bias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "565d04bb-22ed-4dfe-8767-e7fd76ff8f15",
          "showTitle": false,
          "title": ""
        },
        "id": "_2TDHVwwDzTz"
      },
      "source": [
        "#### Comparing a Quantized and Non-Quantized Model\n",
        "\n",
        "Here is a summary of the details and a comparison with the original model:\n",
        "\n",
        "- `Tensor Values`: In the quantized model, these are quantized values of the weights and biases, compared to the original model which stores these in floating point precision. These values are used in the computations performed by the layer, and they directly affect the layer's output.\n",
        "- `Size`: This is the shape of the weight or bias tensor and it should be the same in both the original and quantized model. In a fully-connected layer, this corresponds to the number of neurons in the current layer and the number of neurons in the previous layer.\n",
        "- `Dtype`: In the original model, the data type of the tensor values is usually torch.float32 (32-bit floating point), whereas in the quantized model it is a quantized data type like torch.qint8 (8-bit quantized integer). This reduces the memory usage and computational requirements of the model.\n",
        "- `Quantization_scheme`: This is specific to the quantized model. It is the type of quantization used, for example, torch.per_channel_affine means different channels (e.g., neurons in a layer) can have different scale and zero_point values.\n",
        "- `Scale & Zero Point`: These are parameters of the quantization process and are specific to the quantized model. They are used to convert between the quantized and dequantized forms of the tensor values.\n",
        "- `Axis`: This indicates the dimension along which the quantization parameters vary. This is also specific to the quantized model.\n",
        "- `Requires_grad`: This indicates whether the tensor is a model parameter that is updated during training. It should be the same in both the original and quantized models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "4c0cee67-78d0-4d15-8419-cf9fde5e1817",
          "showTitle": false,
          "title": ""
        },
        "id": "pmIPQHz2DzTz",
        "outputId": "cffe9adb-36d4-430e-d11f-7c19582b32dd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "Command skipped",
              "errorTraceType": "html",
              "metadata": {},
              "type": "ipynbError"
            }
          }
        }
      ],
      "source": [
        "# Suppose we have some input data\n",
        "input_data = torch.randn(1, 28 * 28)\n",
        "\n",
        "# We can pass this data through both the original and quantized models\n",
        "output_original = net(input_data)\n",
        "output_quantized = net_quantized(input_data)\n",
        "\n",
        "# The outputs should be similar, because the quantized model is a lower-precision\n",
        "# approximation of the original model. However, they won't be exactly the same\n",
        "# because of the quantization process.\n",
        "print(\"Output from original model:\", output_original.data)\n",
        "print(\"Output from quantized model:\", output_quantized.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "227b3b46-70bd-486f-bccc-e0e1a579dc7a",
          "showTitle": false,
          "title": ""
        },
        "id": "XkTrF9FmDzTz",
        "outputId": "24f99bb9-778e-450b-dddc-78b2ed071a53"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "Command skipped",
              "errorTraceType": "html",
              "metadata": {},
              "type": "ipynbError"
            }
          }
        }
      ],
      "source": [
        "# The difference between the outputs is an indication of the \"quantization error\",\n",
        "# which is the error introduced by the quantization process.\n",
        "quantization_error = (output_original - output_quantized).abs().mean()\n",
        "print(\"Quantization error:\", quantization_error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "09aa3354-480a-4059-a0cf-47e3492e4e13",
          "showTitle": false,
          "title": ""
        },
        "id": "0X4qOb51DzTz",
        "outputId": "fa2b5462-aaaa-4f92-d98d-3dcd98d6ce14"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "Command skipped",
              "errorTraceType": "html",
              "metadata": {},
              "type": "ipynbError"
            }
          }
        }
      ],
      "source": [
        "# The weights of the original model are stored in floating point precision, so they\n",
        "# take up more memory than the quantized weights. We can check this using the\n",
        "# `element_size` method, which returns the size in bytes of one element of the tensor.\n",
        "print(f\"Size of one weight in original model: {net.fc1.weight.element_size()} bytes (32bit)\")\n",
        "print(f\"Size of one weight in quantized model: {net_quantized.fc1.weight().element_size()} byte (8bit)\")"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "notebookName": "LLM 03 - Deployment of LLMs",
      "widgets": {}
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}