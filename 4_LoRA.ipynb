{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "76e603ea-2f57-4626-aad9-6cbfcb57c104",
          "showTitle": false,
          "title": ""
        },
        "id": "bw3Vyf_aNpBR"
      },
      "source": [
        "# Low-Rank Adaption (LoRA)\n",
        " apply low-rank adaptation (LoRA) to  model of choice using [Parameter-Efficient Fine-Tuning (PEFT) library developed by Hugging Face](https://huggingface.co/docs/peft/index).\n",
        "\n",
        "\n",
        "\n",
        "1. Apply LoRA to a model\n",
        "1. Fine-tune on  provided dataset\n",
        "1. Save  model\n",
        "1. Conduct inference using the fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b552a2ee-9db1-4b4e-adb8-eece97d0bbae",
          "showTitle": false,
          "title": ""
        },
        "id": "UBLfqGA3NpBS",
        "outputId": "22865059-9db8-4578-be66-3918c15f18df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\nCollecting peft==0.4.0\n  Using cached peft-0.4.0-py3-none-any.whl (72 kB)\nRequirement already satisfied: pyyaml in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0) (6.0)\nRequirement already satisfied: transformers in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0) (4.29.2)\nRequirement already satisfied: torch>=1.13.0 in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0) (1.13.1+cpu)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0) (21.3)\nRequirement already satisfied: numpy>=1.17 in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0) (1.21.5)\nCollecting safetensors\n  Using cached safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\nRequirement already satisfied: accelerate in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0) (0.19.0)\nRequirement already satisfied: psutil in /databricks/python3/lib/python3.10/site-packages (from peft==0.4.0) (5.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.10/site-packages (from packaging>=20.0->peft==0.4.0) (3.0.9)\nRequirement already satisfied: typing-extensions in /databricks/python3/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (4.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /databricks/python3/lib/python3.10/site-packages (from transformers->peft==0.4.0) (0.15.1)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.10/site-packages (from transformers->peft==0.4.0) (2.28.1)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from transformers->peft==0.4.0) (3.6.0)\nRequirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.10/site-packages (from transformers->peft==0.4.0) (2022.7.9)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /databricks/python3/lib/python3.10/site-packages (from transformers->peft==0.4.0) (0.13.3)\nRequirement already satisfied: tqdm>=4.27 in /databricks/python3/lib/python3.10/site-packages (from transformers->peft==0.4.0) (4.64.1)\nRequirement already satisfied: fsspec in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft==0.4.0) (2022.7.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0) (1.26.11)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0) (2022.9.14)\nInstalling collected packages: safetensors, peft\nSuccessfully installed peft-0.4.0 safetensors-0.3.2\n\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%pip install peft==0.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "bb87720c-36b9-4446-bb81-b5324ed13fab",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "referenced_widgets": [
            "86ff474dcc7d425b9ee9878323a99818"
          ]
        },
        "id": "95_ZrKf8NpBT",
        "outputId": "042f8587-0338-4f81-e62b-06e54701220b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/databricks/python_shell/dbruntime/huggingface_patches/datasets.py:13: UserWarning: During large dataset downloads, there could be multiple progress bar widgets that can cause performance issues for your notebook or browser. To avoid these issues, use `datasets.utils.logging.disable_progress_bar()` to turn off the progress bars.\n  warnings.warn(\nFound cached dataset json (/dbfs/mnt/dbacademy-datasets/llm-foundation-models/v01-raw/datasets/Abirate___json/Abirate--english_quotes-6e72855d06356857/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86ff474dcc7d425b9ee9878323a99818",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /dbfs/mnt/dbacademy-datasets/llm-foundation-models/v01-raw/datasets/Abirate___json/Abirate--english_quotes-6e72855d06356857/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-768c685e1cb83483.arrow\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['quote', 'author', 'tags', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 50\n",
              "})"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"bigscience/bloomz-560m\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "foundation_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "data = load_dataset(\"Abirate/english_quotes\", cache_dir=DA.paths.datasets+\"/datasets\")\n",
        "data = data.map(lambda samples: tokenizer(samples[\"quote\"]), batched=True)\n",
        "train_sample = data[\"train\"].select(range(50))\n",
        "display(train_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "4eefcf80-dc96-4178-aab7-bd70c9ba1c34",
          "showTitle": false,
          "title": ""
        },
        "id": "SwqPM-z-NpBU"
      },
      "outputs": [],
      "source": [
        "\n",
        "import peft\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=1,\n",
        "    lora_alpha=1, # a scaling factor that adjusts the magnitude of the weight matrix. Usually set to 1\n",
        "    target_modules=[\"query_key_value\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\", # this specifies if the bias parameter should be trained.\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8bd497af-5c5f-4747-8c95-4815d59e6937",
          "showTitle": false,
          "title": ""
        },
        "id": "3GUa-G0uNpBV",
        "outputId": "62549004-818a-4446-dd1f-f82615a4923a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 98,304 || all params: 559,312,896 || trainable%: 0.01757585078102687\nNone\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#model, peft_config, lora_config\n",
        "peft_model = get_peft_model(foundation_model,lora_config)\n",
        "print(peft_model.print_trainable_parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "0aa020a3-d5b3-4af1-8acd-0e08ad691682",
          "showTitle": false,
          "title": ""
        },
        "id": "_1BhgT6qNpBW"
      },
      "source": [
        "## Define `Trainer` class for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "5941ae37-cef8-4154-8011-6a56adc9671a",
          "showTitle": false,
          "title": ""
        },
        "id": "IskauH8vNpBW",
        "outputId": "22d2a0a3-0218-4418-ba7e-445b73bde60e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 02:11, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=7, training_loss=4.56964956011091, metrics={'train_runtime': 140.7924, 'train_samples_per_second': 0.355, 'train_steps_per_second': 0.05, 'total_flos': 12037198331904.0, 'train_loss': 4.56964956011091, 'epoch': 1.0})"
            ]
          },
          "execution_count": 32,
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "import transformers\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import os\n",
        "\n",
        "output_directory = os.path.join(DA.paths.working_dir, \"peft_lab_outputs\")\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_directory,\n",
        "    auto_find_batch_size=True,\n",
        "    learning_rate= 3e-2, # Higher learning rate than full fine-tuning.\n",
        "    num_train_epochs=1,\n",
        "    no_cuda=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_sample,\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "92a88287-8f87-4b63-8fff-13f037501c41",
          "showTitle": false,
          "title": ""
        },
        "id": "Bf3dpPn-NpBX"
      },
      "source": [
        "## Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "9c03de43-9600-4cf0-8776-04a136fe3841",
          "showTitle": false,
          "title": ""
        },
        "id": "H0IN_4BJNpBX"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "time_now = time.time()\n",
        "\n",
        "username = spark.sql(\"SELECT CURRENT_USER\").first()[0]\n",
        "peft_model_path = os.path.join(output_directory, f\"peft_model_{time_now}\")\n",
        "\n",
        "trainer.model.save_pretrained(peft_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "58e67b60-7742-476e-a11a-8cf1afb02b4d",
          "showTitle": false,
          "title": ""
        },
        "id": "9NFYFfeBNpBX"
      },
      "outputs": [],
      "source": [
        "\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "loaded_model = PeftModel.from_pretrained(foundation_model,peft_model_path,\n",
        " is_trainable=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "082438f6-f825-4552-8a5e-7a5503919da1",
          "showTitle": false,
          "title": ""
        },
        "id": "qaeY9vd5NpBY"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "010630ef-b4ad-4c6d-8bd3-38b0a0769a2c",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "MI1rgG4vNpBY",
        "outputId": "f1912e7d-f392-41b7-fa09-767b23ee26a2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-de174a3fca36>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Two things are infinite: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m outputs = peft_model.generate(\n\u001b[1;32m      4\u001b[0m     \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "inputs = tokenizer(\"Two things are infinite: \", return_tensors=\"pt\")\n",
        "outputs = peft_model.generate(\n",
        "    input_ids=inputs[\"input_ids\"],\n",
        "    attention_mask=inputs[\"attention_mask\"],\n",
        "    max_new_tokens=5,\n",
        "    #eos_token_id=tokenizer.eos_id\n",
        "    )\n",
        "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "notebookName": "LLM 02L - LoRA with PEFT",
      "widgets": {}
    },
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}